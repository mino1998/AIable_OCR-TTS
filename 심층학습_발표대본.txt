1p.
안녕하십니까 OCR기술 기반 시각애인 도움 서비스 발표를 맡게 될 AIable의 000입니다.

2p.
일정계획, 필요성, 주제, 기술설명과 그에 대한 알고리즘 설명 및 시연연상을 보여드리고,
이 기술을 어떻게 사업화할 것인지, 지금 저희 기술의 한계와 발전가능성에 대해 말씀드리겠습니다.

3p.
4p.
영상에서 보셨듯, 시각장애인들이 제품을 구매하는데 어려움을 겪는 것을 볼 수 있습니다.
.
5p.
영상에서는 시각장애인이 점자가 있으면 자유롭게 살 수 있을까? 라고 말합니다. 현재 제공되고 있는 제품엔 점자표기가 한정되있고, 점자가 표기된 경우, 제품설명이 매우 부족한 것을 알 수 있습니다.
예를들어 맥스, 하이트, 카스등 다양한 맥주가 존재하지만 실제 제공되는 점자는 맥주 하나로 통일되어 시각장애인이 불편을 겪고있습니다.
점자가 제공되는 제품이라도 시각장애인 점자 문맹률이 86%에 육박하여 실제 시각장애인이 이용하기 어려운 현실입니다. https://www.idomin.com/news/articleView.html?idxno=772046

또한 지금 제공되는 시각장애인을 위한 앱인 설리번플러스, 씨잉 에이아이등은 튜토리얼 진행 시 음성으로 제공이 되지 않아, 실제 이용자가 주변 도움 없이는 사용하기 어려운 점을 볼 수 있었습니다.

6p
이에 착안하여 시각장애인을 위한 제품 문자 식별 서비스를 만들게 되었습니다.

7p

8페이지
저희 서비스는 Tesseract 라이브러리와 TTS 기술을 이용합니다. 먼저 Tesseract란 LSTM 기반 엔진으로 구현된 OCR 오픈소스 라이브러리입니다. OCR이란 Optimal Character Recognition의 줄임말로, 사람이 직접 쓰거나 이미지 속에 있는 문자를 이미지 스캔으로 얻은 다음, 이를 컴퓨터로 인식할 수 있도록 문자를 디지털화 하는 기술입니다. Tesseract는 이미지 학습에 LSTM을 이용하는데, LSTM이란 RNN의 한 종류로 긴 문자열이 포함된 이미지의 인식에 적합한 모델입니다.



9페이지
LSTM에 대해 알아보기에 앞서 RNN에 대해 살펴보겠습니다. RNN이란 인공신경망의 한 종류로, Hidden state가 방향을 가진 edge로 연결되어 순환 구조를 이룹니다. 문장과 같은 시퀀스 데이터를 분석하는 데 유용하며, Input과 Output의 길이에 제약받지 않고 유연한 구조를 가질 수 있다는 장점이 있습니다. 필요한 정보를 얻기 위한 시간 격차가 크지 않다면 RNN도 지난 정보를 바탕으로 학습할 수 있습니다. 하지만 더 많은 문맥을 필요로 하는 경우, 정보를 얻기 위한 시간 격차는 늘어나며 이 격차가 클수록 RNN은 학습하는 정보를 계속 이어나가기 힘듭니다. LSTM은 이러한 긴 기간 의존성 문제 해결을 위해 탄생하였으며, RNN의 짧은 의존 기간을 극복할 수 있었습니다.

10페이지
LSTM은 긴 의존 기간을 필요로 하는 학습을 수행할 능력을 가지고 있습니다. RNN과 같이 체인 구조로 이루어져 있지만, RNN과 같이 단순한 뉴럴 네트워크 한 층 대신 기본 LSTM 모델의 경우 4개의 레이어가 서로 정보를 주고 받는 구조로 이루어져 있습니다.
(분량 모자랄 경우 추가, 분량이 충분한 경우 생략 - 이 4개의 레이어는 어떤 정보를 버릴 것인지를 정하는 forget gate 레이어, 새로운 정보 중 어떤 것을 cell state에 저장할 것인지를 정하는 input gate 레이어, 과거 state를 업데이트해서 새로운 cell state를 만드는 cell state update 레이어, 무엇을 output으로 내보낼지 정하는 output gate 레이어로 구성되어 있습니다.)

11페이지
두 번째로 사용되는 기술인 TTS는 사람의 말소리를 기계가 만들어주는 기술로, 저희 서비스에서는 구글 텍스트 음성 변환 라이브러리인 gTTS를 사용하였습니다.

12페이지
저희 서비스의 순서는 크게 Tesseract 학습, OCR, TTS로 나뉘며, Tesseract 학습 단계에서는 이미지 데이터 수집 후 Tesseract에서 제공되는 Trained data를 이용합니다. OCR 단계에서는 카메라로 입력된 영상 데이터에서 Tesseract 모델을 이용하여 문자를 탐지하고, 문자의 아웃라인을 추출하여 특징점을 획득한 후, 검색을 통해 Tesseract 데이터베이스의 템플릿과 매칭하여 오차율이 가장 낮은 문자를 선택하게 됩니다. 이후 TTS 단계에서는 Tesseract에서 나온 문자열을 input으로 받아 gTTS를 이용하여 음성을 합성한 후 출력합니다.


13페이지
OCR단계에서 카메라로 영상 데이터를 받을 시에는 이미지를 전처리 후 세그멘테이션 작업을 하게 됩니다.

14페이지
이후 Tesseract가 원래의 이미지에 outline을 생성하여 문자의 특징점을 추출한 후 데이터베이스 검색을 통해 특징점이 비슷한 문자들과의 템플릿 매칭 후 원본 이미지와의 오차율이 가장 낮은 문자를 선택합니다.

15페이지
시연 영상을 보시겠습니다.
16p 
다음으로 사업화 가능성에 대해 설명 드리겟습니다.

17p
AIable의 경우 복지의 성격이 큰 앱으로 수익을 창출하기 어려운 구조입니다.
기존에 서울시에서 진행한 시각장애인을 위한 복지서비스인 엔젤아이즈를 보고 공익 사업으로 접근하면 되겠다 판단하였습니다.

18p
먼저 나라장터를 통해 입찰 방식으로 진행하는 방법


19p
정부 및 지자체 공익 사업 공모를 통하여 진행하는 방법이 있습니다.
이 경우 대부분 비영리법인/ 민간단체를 통하여 공모가 진행되어 AIable을 비영리법인/민간단체에 제안하여 공익 사업을 추진하는 방법을 고안했습니다.
실제로 올해 진행되는 공익사업 공모의 자세한 내용은 위의 사이트에서 확인할 수 있으며, 저희와 적합한 곳은 행정안전부, 서울특별시, 국가인권위원회 등이 있습니다.

20p
두 번째로, 민간재단 공익사업에 공모하는 것입니다. 방식응 정부 및 지자체 공모와 동일하며, 저희와 적합한 재단은 사회복지공동모금회, 재단법인동천, 아산 사회복지재단 등이 있습니다.

21p.
앞에서 말한 나라장터를 통한 입찰방식에서 애초에 저희가 원하는 사업의 공고가 나지 않는 경우, 기업의 공익 사업을 통해 진행하는 방법을 고안하였습니다.

22p
이 경우, 기술을 기업에 제공하여 기술료를 받고, 기업에서는 이 기술을 통한 앱을 시각장애인에게 제공하여 사회적 공헌을 통한 기업의 이미지 개선으로 수익을 높일 수 있다 판단하였습니다. 

23p
아직 저희 기술은 앱으로 미구현 된 상태이며, 학습데이터가 부족하여 제품의 글자 인식률이 미흡한 상태입니다.



24p
추후 제품사진 데이터셋을 충분히 축적 후 학습을 통해 제품글자인식률을 향상시킬 예정입니다. 또한 어플리케이션 구현 시, 음성 인식 리모트 컨트롤 기능을 추가하여, 기존 어플리케이션과 차이점을 두어 실제 사용자인 시각장애인이 기능을 직접 구현 할 수 있도록 하는 것이 목표입니다.

25p 
감사합니다.~


